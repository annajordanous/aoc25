{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053f06d2",
   "metadata": {},
   "source": [
    "--- Day 11: Reactor ---\n",
    "You hear some loud beeping coming from a hatch in the floor of the factory, so you decide to check it out. Inside, you find several large electrical conduits and a ladder.\n",
    "\n",
    "Climbing down the ladder, you discover the source of the beeping: a large, toroidal reactor which powers the factory above. Some Elves here are hurriedly running between the reactor and a nearby server rack, apparently trying to fix something.\n",
    "\n",
    "One of the Elves notices you and rushes over. \"It's a good thing you're here! We just installed a new server rack, but we aren't having any luck getting the reactor to communicate with it!\" You glance around the room and see a tangle of cables and devices running from the server rack to the reactor. She rushes off, returning a moment later with a list of the devices and their outputs (your puzzle input).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6850ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "['iak: edr ehw kqn vjh', 'awq: sfz nys cio jzi gtt', 'nes: sqf ist mux', 'jik: out', 'kie: pzi', 'myb: cjq', 'wvy: pmr kqw aao hja', 'laa: kpq xgo sks', 'yyj: lpz rpn apc', 'cee: vjh kqn ehw edr']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "elf_data = []\n",
    "\n",
    "with open('day11.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        elf_data.append(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "print(len(elf_data))\n",
    "print(elf_data[0:10])\n",
    "print(type(elf_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fca0a2-342b-47b5-8edf-e5a3c782f147",
   "metadata": {},
   "source": [
    "For example:\n",
    "\n",
    "aaa: you hhh\n",
    "you: bbb ccc\n",
    "bbb: ddd eee\n",
    "ccc: ddd eee fff\n",
    "ddd: ggg\n",
    "eee: out\n",
    "fff: out\n",
    "ggg: out\n",
    "hhh: ccc fff iii\n",
    "iii: out\n",
    "Each line gives the name of a device followed by a list of the devices to which its outputs are attached. So, bbb: ddd eee means that device bbb has two outputs, one leading to device ddd and the other leading to device eee.\n",
    "\n",
    "The Elves are pretty sure that the issue isn't due to any specific device, but rather that the issue is triggered by data following some specific path through the devices. Data only ever flows from a device through its outputs; it can't flow backwards.\n",
    "\n",
    "After dividing up the work, the Elves would like you to focus on the devices starting with the one next to you (an Elf hastily attaches a label which just says you) and ending with the main output to the reactor (which is the device with the label out).\n",
    "\n",
    "To help the Elves figure out which path is causing the issue, they need you to find every path from you to out.\n",
    "\n",
    "In this example, these are all of the paths from you to out:\n",
    "\n",
    "Data could take the connection from you to bbb, then from bbb to ddd, then from ddd to ggg, then from ggg to out.\n",
    "Data could take the connection to bbb, then to eee, then to out.\n",
    "Data could go to ccc, then ddd, then ggg, then out.\n",
    "Data could go to ccc, then eee, then out.\n",
    "Data could go to ccc, then fff, then out.\n",
    "In total, there are 5 different paths leading from you to out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63c33a6-992a-47bf-a258-8716b2d35179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['aaa: you hhh', 'you: bbb ccc', 'bbb: ddd eee', 'ccc: ddd eee fff', 'ddd: ggg', 'eee: out', 'fff: out', 'ggg: out', 'hhh: ccc fff iii', 'iii: out']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = []\n",
    "\n",
    "with open('test11.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        test_data.append(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "print(len(test_data))\n",
    "print(test_data)\n",
    "print(type(test_data))\n",
    "\n",
    "\n",
    "test_data2 = []\n",
    "with open('test11_2.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        test_data2.append(line.replace(\"\\n\", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899232cb",
   "metadata": {},
   "source": [
    "How many different paths lead from you to out?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2d4bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b3852b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    graph_data = {}\n",
    "    for d in data:\n",
    "        temp = d.split(\": \")\n",
    "        graph_data.update({temp[0]: temp[1].split(\" \")})\n",
    "    G = nx.from_dict_of_lists(graph_data, create_using = nx.DiGraph)\n",
    "    return G\n",
    "        \n",
    "test_graph = process_data(test_data)\n",
    "test_graph2 = process_data(test_data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2866e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "elf_graph = process_data(elf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac887390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaa', 'you', 'bbb', 'ccc', 'ddd', 'eee', 'fff', 'ggg', 'hhh', 'iii', 'out']\n",
      "[('aaa', 'you'), ('aaa', 'hhh'), ('you', 'bbb'), ('you', 'ccc'), ('bbb', 'ddd'), ('bbb', 'eee'), ('ccc', 'ddd'), ('ccc', 'eee'), ('ccc', 'fff'), ('ddd', 'ggg'), ('eee', 'out'), ('fff', 'out'), ('ggg', 'out'), ('hhh', 'ccc'), ('hhh', 'fff'), ('hhh', 'iii'), ('iii', 'out')]\n",
      "['svr', 'aaa', 'fft', 'bbb', 'tty', 'ccc', 'ddd', 'hub', 'eee', 'dac', 'fff', 'ggg', 'hhh', 'out']\n",
      "[('svr', 'aaa'), ('svr', 'bbb'), ('aaa', 'fft'), ('fft', 'ccc'), ('bbb', 'tty'), ('tty', 'ccc'), ('ccc', 'ddd'), ('ccc', 'eee'), ('ddd', 'hub'), ('hub', 'fff'), ('eee', 'dac'), ('dac', 'fff'), ('fff', 'ggg'), ('fff', 'hhh'), ('ggg', 'out'), ('hhh', 'out')]\n"
     ]
    }
   ],
   "source": [
    "print(test_graph.nodes)\n",
    "print(test_graph.edges)\n",
    "\n",
    "print(test_graph2.nodes)\n",
    "print(test_graph2.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1adced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_all_paths(graph, start, finish):\n",
    "    return list(nx.all_simple_paths(graph, start, finish,len(graph.nodes)))\n",
    "    \n",
    "\n",
    "print(len(find_all_paths(test_graph, 'you', 'out')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1da3f2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634\n"
     ]
    }
   ],
   "source": [
    "print(len(find_all_paths(elf_graph,  'you', 'out')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a6b286",
   "metadata": {},
   "source": [
    "--- Part Two ---\n",
    "Thanks in part to your analysis, the Elves have figured out a little bit about the issue. They now know that the problematic data path passes through both dac (a digital-to-analog converter) and fft (a device which performs a fast Fourier transform).\n",
    "\n",
    "They're still not sure which specific path is the problem, and so they now need you to find every path from svr (the server rack) to out. However, the paths you find must all also visit both dac and fft (in any order).\n",
    "\n",
    "For example:\n",
    "\n",
    "svr: aaa bbb\n",
    "aaa: fft\n",
    "fft: ccc\n",
    "bbb: tty\n",
    "tty: ccc\n",
    "ccc: ddd eee\n",
    "ddd: hub\n",
    "hub: fff\n",
    "eee: dac\n",
    "dac: fff\n",
    "fff: ggg hhh\n",
    "ggg: out\n",
    "hhh: out\n",
    "This new list of devices contains many paths from svr to out:\n",
    "\n",
    "svr,aaa,fft,ccc,ddd,hub,fff,ggg,out\n",
    "svr,aaa,fft,ccc,ddd,hub,fff,hhh,out\n",
    "svr,aaa,fft,ccc,eee,dac,fff,ggg,out\n",
    "svr,aaa,fft,ccc,eee,dac,fff,hhh,out\n",
    "svr,bbb,tty,ccc,ddd,hub,fff,ggg,out\n",
    "svr,bbb,tty,ccc,ddd,hub,fff,hhh,out\n",
    "svr,bbb,tty,ccc,eee,dac,fff,ggg,out\n",
    "svr,bbb,tty,ccc,eee,dac,fff,hhh,out\n",
    "However, only 2 paths from svr to out visit both dac and fft.\n",
    "\n",
    "Find all of the paths that lead from svr to out. How many of those paths visit both dac and fft?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8110c48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def through_dac_and_fft(graph):\n",
    "    paths = find_all_paths(graph, 'svr', 'out')\n",
    "    valid_paths = [p for p in paths if 'fft' in p and 'dac' in p]\n",
    "#    valid_paths2 = [p for p in paths if 'dac' in p]\n",
    "    return valid_paths#, valid_paths2\n",
    "\n",
    "\n",
    "\n",
    "print(len(through_dac_and_fft(test_graph2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573be1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['svr', 'aaa', 'fft', 'bbb', 'tty', 'ccc', 'ddd', 'hub', 'eee', 'dac', 'fff', 'ggg', 'hhh', 'out']\n",
      "sd\n",
      "hello\n",
      "sf\n",
      "hello\n",
      "df\n",
      "fd\n",
      "hello\n",
      "fo\n",
      "hello\n",
      "hello\n",
      "do\n",
      "hello\n",
      "hello\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "def quicker(graph):\n",
    "#     n = len(graph.nodes)\n",
    "#     sd_path = nx.all_simple_paths(graph, 'svr', 'dac', (n-2))\n",
    "#     print('sd_path ', sd_path)\n",
    "#     sd_count = count_not_in(sd_path, 'fft')\n",
    "\n",
    "#     sf_path = nx.all_simple_paths(graph, 'svr', 'fft', (n-2))\n",
    "#     print('sf_path ', sf_path)\n",
    "#     sf_count = count_not_in(sf_path, 'dac')\n",
    "\n",
    "#     df_path = nx.all_simple_paths(graph, 'dac', 'fft', (n-2))\n",
    "#     print('df_path ', df_path)\n",
    "#     df_count = count_not_in(df_path, 'BOGEY')\n",
    "\n",
    "\n",
    "#     fd_path = nx.all_simple_paths(graph, 'fft', 'dac', (n-2))\n",
    "#     print('fd_path ', fd_path)\n",
    "#     fd_count = count_not_in(fd_path, 'BOGEY')\n",
    "    \n",
    "#     do_path = nx.all_simple_paths(graph, 'dac', 'out', (n-2))\n",
    "#     print('do_path ', do_path)\n",
    "#     do_count = count_not_in(do_path, 'fft')\n",
    "\n",
    "#     fo_path = nx.all_simple_paths(graph, 'fft', 'out', (n-2))\n",
    "#     print('fo_path ', fo_path)\n",
    "#     fo_count = count_not_in(fo_path, 'dac')\n",
    "\n",
    "\n",
    "#     sd = next(sd_count)\n",
    "#     sf = next(sf_count)\n",
    "#     df = next(df_count)\n",
    "#     fd = next(fd_count)\n",
    "#     do = next(do_count)\n",
    "#     fo = next(fo_count)\n",
    "    \n",
    "#     paths_sdfo = sd * df * fo\n",
    "#     paths_sfdo = sf * fd * fo\n",
    "                                                    \n",
    "#     return paths_sdfo+paths_sfdo\n",
    "\n",
    "    other_nodes = list(graph.nodes)\n",
    "    other_nodes.remove('svr')\n",
    "    other_nodes.remove('fft')\n",
    "    other_nodes.remove('dac')\n",
    "    other_nodes.remove('out')\n",
    "    #print(other_nodes+['svr','dac'])\n",
    "    #print(other_nodes+['out','fft'])\n",
    "    Gsd = graph.subgraph(other_nodes+['svr','dac'].copy())\n",
    "    Gsf = graph.subgraph(other_nodes+['svr','fft'].copy())\n",
    "    Gdf = graph.subgraph(other_nodes+['dac','fft'].copy())\n",
    "    Gfd = graph.subgraph(other_nodes+['fft','dac'].copy())\n",
    "    Gfo = graph.subgraph(other_nodes+['fft','out'].copy())\n",
    "    Gdo = graph.subgraph(other_nodes+['dac', 'out'].copy())\n",
    "    print(graph.nodes)\n",
    "    print(\"sd\")\n",
    "    sd = count_in2(nx.all_simple_paths(Gsd, 'svr', 'dac', len(Gsd.nodes)))\n",
    "    print(\"sf\")\n",
    "    sf = count_in2(nx.all_simple_paths(Gsf, 'svr', 'fft', len(Gsf.nodes)))\n",
    "    print(\"df\")\n",
    "    df = count_in2(nx.all_simple_paths(Gdf, 'dac', 'fft', len(Gdf.nodes)))\n",
    "    print(\"fd\")\n",
    "    fd = count_in2(nx.all_simple_paths(Gfd, 'fft', 'dac', len(Gfd.nodes)))\n",
    "    print(\"fo\")\n",
    "    fo = count_in2(nx.all_simple_paths(Gfo, 'fft', 'out', len(Gfo.nodes)))\n",
    "    print(\"do\")\n",
    "    do = count_in2(nx.all_simple_paths(Gdo, 'dac', 'out', len(Gdo.nodes)))\n",
    "\n",
    "\n",
    "\n",
    "    paths_sdfo = sd * df * fo\n",
    "    paths_sfdo = sf * fd * fo\n",
    "                                                  \n",
    "    return paths_sdfo+paths_sfdo\n",
    "\n",
    "\n",
    "def count_in(path_gen):\n",
    "    return sum(1 for _ in path_gen)\n",
    "\n",
    "def count_in2(path_gen):\n",
    "    count = 0\n",
    "    for _ in path_gen:\n",
    "        print(\"hello\")\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "print(quicker(test_graph2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea3392e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0721d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(through_dac_and_fft(elf_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8f28d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iak', 'awq', 'nes', 'jik', 'kie', 'myb', 'wvy', 'laa', 'yyj', 'cee', 'guq', 'lmu', 'ypf', 'odx', 'ywl', 'bpw', 'jvl', 'pjr', 'lsp', 'llq', 'jtg', 'mxo', 'kyu', 'ahk', 'pxm', 'unz', 'lgx', 'tos', 'aow', 'thm', 'nas', 'sow', 'idj', 'ftt', 'foe', 'fzg', 'mpk', 'wck', 'jev', 'yon', 'zcg', 'vhv', 'fwm', 'uil', 'laj', 'xwl', 'tks', 'hpf', 'lpz', 'ukf', 'nog', 'arm', 'jqq', 'zbb', 'xfw', 'mgp', 'xlv', 'llu', 'hna', 'fja', 'mux', 'add', 'kcf', 'zim', 'geo', 'khq', 'xgd', 'yja', 'bok', 'xgo', 'dqc', 'szj', 'cgr', 'fel', 'ikv', 'ewe', 'dty', 'rpx', 'gbl', 'pzb', 'txi', 'jeb', 'hds', 'pwa', 'ylr', 'jbm', 'gds', 'izo', 'nbx', 'gqh', 'tfc', 'yil', 'xse', 'tbc', 'tdx', 'dac', 'vkx', 'arf', 'njj', 'tql', 'jmo', 'ywn', 'lvf', 'nfn', 'zuv', 'cxx', 'akw', 'wjc', 'bjg', 'fft', 'yfs', 'oix', 'mqv', 'rtn', 'erv', 'yea', 'raf', 'kbm', 'sah', 'lty', 'nzl', 'jdc', 'bws', 'swx', 'wjh', 'wcq', 'wcg', 'tmy', 'wtb', 'zpt', 'zyx', 'zhk', 'haz', 'lfb', 'hwz', 'wpr', 'llv', 'pcn', 'cmw', 'dmd', 'rmc', 'bwn', 'fzi', 'vnt', 'maz', 'kab', 'vyn', 'zjh', 'wzi', 'ary', 'ffl', 'ire', 'zyz', 'sks', 'sfz', 'svr', 'dmg', 'mih', 'dry', 'wrm', 'jin', 'uaz', 'jwg', 'vbm', 'ist', 'ymm', 'hpe', 'wpc', 'viw', 'zrh', 'dxx', 'ftr', 'yac', 'qni', 'xpd', 'wfw', 'mfh', 'xgu', 'ude', 'ijh', 'xgz', 'dsa', 'ias', 'gak', 'goz', 'tjw', 'apc', 'yxl', 'qzj', 'pyd', 'xpw', 'wdc', 'bod', 'qex', 'fds', 'tva', 'deo', 'you', 'gpr', 'daf', 'mea', 'iui', 'niy', 'cnd', 'fer', 'gtt', 'keb', 'gjz', 'ywh', 'qnl', 'wmz', 'fjz', 'bci', 'wfg', 'art', 'ykd', 'nld', 'tfz', 'fzj', 'ucr', 'jdr', 'tow', 'wan', 'nnc', 'rix', 'nve', 'xex', 'bjb', 'tne', 'qdo', 'zya', 'wee', 'sqf', 'hxn', 'qio', 'dem', 'znb', 'imk', 'rbd', 'ics', 'xal', 'fnx', 'bhl', 'zkg', 'hah', 'fmu', 'sou', 'yft', 'ywr', 'alu', 'cix', 'hxq', 'dme', 'axj', 'ryo', 'foy', 'luw', 'apl', 'tgs', 'uuw', 'rhs', 'moa', 'sys', 'kzx', 'twj', 'fqu', 'agd', 'gmv', 'lju', 'aja', 'ajb', 'pub', 'fda', 'lpe', 'uvw', 'kji', 'fml', 'zca', 'fji', 'thz', 'dcp', 'til', 'jqj', 'lav', 'vod', 'gpv', 'fuq', 'hnt', 'khg', 'nmj', 'ccl', 'srh', 'inh', 'fpi', 'zyi', 'occ', 'wzj', 'tkh', 'aza', 'jeo', 'kuj', 'nys', 'nky', 'iki', 'yzh', 'vfw', 'zoa', 'eqb', 'jic', 'iga', 'bdo', 'xjb', 'brf', 'wbq', 'lau', 'dhp', 'nwe', 'acx', 'cio', 'rnt', 'pmr', 'rhh', 'ypb', 'vsg', 'xzg', 'nen', 'zgm', 'hid', 'wif', 'ivd', 'ahi', 'cwf', 'qcc', 'wyw', 'gnk', 'ixx', 'rpn', 'seg', 'qfp', 'kpq', 'vjm', 'kqw', 'aju', 'ish', 'qeo', 'wyy', 'bhq', 'zrc', 'eew', 'jxp', 'xry', 'qak', 'jle', 'rlr', 'lgp', 'psw', 'sbj', 'vdk', 'vqz', 'bic', 'pzi', 'ehw', 'agi', 'avb', 'xgm', 'hry', 'jwx', 'wdb', 'jpa', 'qfh', 'ltb', 'jwr', 'mfl', 'wmp', 'yau', 'rct', 'bno', 'hxp', 'duj', 'ugk', 'oko', 'dbb', 'wmk', 'syb', 'dzg', 'kww', 'ufx', 'unm', 'ayn', 'inj', 'eve', 'zod', 'uwp', 'nlm', 'yda', 'ojp', 'mrd', 'zxb', 'mdy', 'vht', 'qpo', 'bqq', 'pyn', 'xfg', 'yve', 'usf', 'wgr', 'cwj', 'zah', 'mcq', 'vnj', 'rds', 'oku', 'glp', 'bpo', 'cjc', 'pjv', 'blo', 'lyo', 'ydb', 'rqa', 'wtt', 'rsb', 'kqn', 'bhd', 'svm', 'skn', 'rad', 'vjh', 'qkf', 'edr', 'gkw', 'she', 'lpw', 'inv', 'ruq', 'vno', 'cyx', 'zvc', 'heb', 'nrn', 'las', 'jfu', 'uvd', 'tfb', 'nga', 'rpy', 'emh', 'qek', 'vwx', 'fua', 'cib', 'obm', 'qtd', 'qus', 'rul', 'rqr', 'qub', 'vsy', 'sdo', 'hpx', 'ijf', 'wcd', 'wpb', 'ftw', 'nqy', 'wtp', 'cge', 'kta', 'ltq', 'rxy', 'wrv', 'lvu', 'nje', 'rrq', 'nke', 'dds', 'egq', 'nzf', 'rjq', 'nmb', 'ris', 'egu', 'gpt', 'pld', 'lce', 'lvl', 'jzi', 'ynx', 'omz', 'mnc', 'nvd', 'hja', 'cpq', 'fsf', 'cjq', 'frt', 'dyg', 'sgb', 'dvw', 'ayr', 'hln', 'bln', 'hgk', 'xkv', 'vjc', 'wza', 'jjp', 'dnp', 'myn', 'lun', 'azd', 'zwz', 'ssj', 'uby', 'tom', 'xmu', 'jmw', 'zdn', 'crg', 'buw', 'xvb', 'eth', 'qpi', 'xmh', 'uiq', 'jkp', 'fek', 'pim', 'kex', 'jgi', 'jqm', 'tyh', 'tch', 'rgz', 'chi', 'zpy', 'fcc', 'uju', 'ame', 'kit', 'kqc', 'wok', 'pra', 'jyw', 'yam', 'ogc', 'gga', 'fls', 'dre', 'xkb', 'aji', 'beh', 'dqi', 'xct', 'qhy', 'xxc', 'skq', 'afr', 'ctu', 'qql', 'kxv', 'emo', 'smd', 'pjc', 'shl', 'wcx', 'xgg', 'ege', 'lzg', 'krb', 'mvt', 'jhw', 'uqj', 'bik', 'jnd', 'xkg', 'aao', 'pnz', 'lvd', 'ihb', 'yhn', 'sov', 'ffz', 'muy', 'jen', 'ewv', 'ctx', 'bsr', 'zri', 'hte', 'yyb', 'ytb', 'nij', 'ars', 'xxv', 'yyn', 'yku', 'hta', 'dll', 'mhl', 'yzr', 'hcj', 'eip', 'wdd', 'tvi', 'eua', 'lnp', 'xwo', 'out']\n",
      "sd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(quicker(elf_graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
